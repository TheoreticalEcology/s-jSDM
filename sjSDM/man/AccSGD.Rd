% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sjSDM_configs.R
\name{AccSGD}
\alias{AccSGD}
\title{AccSGD}
\usage{
AccSGD(kappa = 1000, xi = 10, small_const = 0.7, weight_decay = 0)
}
\arguments{
\item{kappa}{long step}

\item{xi}{advantage parameter}

\item{small_const}{small constant}

\item{weight_decay}{l2 penalty on weights}
}
\value{
Anonymous function that returns optimizer when called.
}
\description{
accelerated stochastic gradient, see Kidambi et al., 2018 for details
}
\references{
Kidambi, R., Netrapalli, P., Jain, P., & Kakade, S. (2018, February). On the insufficiency of existing momentum schemes for stochastic optimization. In 2018 Information Theory and Applications Workshop (ITA) (pp. 1-9). IEEE.
}
